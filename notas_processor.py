"""M√≥dulo de processamento de notas"""
import os
import re

import faiss

def extrair_conceitos_relevantes(nlp, text, stopwords):
    """Extrai conceitos-chave de um texto utilizando PLN

    Analisa o texto com um pipeline de linguagem natural (spaCy) e retorna uma lista de conceitos
    relevantes (substantivos e nomes pr√≥prios) em min√∫sculas, filtrando palavras curtas e stopwords.
    """
    try:
        if not text or not isinstance(text, str):
            return []
        doc = nlp(text)
        concepts = set()
        for token in doc:
            if token.pos_ in ('NOUN', 'PROPN') and len(token.text.strip()) > 3:
                clean_concept = re.sub(r'[^\w\s-]', '', token.text).lower().strip()
                if clean_concept and clean_concept not in stopwords:
                    concepts.add(clean_concept)
        return list(concepts)
    except Exception as e:
        print(f"Erro na extra√ß√£o de conceitos: {str(e)}")
        return []

def verificar_conexoes_relevantes(conceito, conteudo):
    """Verifica se um conceito aparece de forma relevante dentro do conte√∫do fornecido.

    Retorna True se o conceito estiver presente no conte√∫do do texto. 

    Fun√ß√£o ainda por desenvover (21 de abril a 11 de maio de 2025)
    """
    if conceito in conteudo:
        return True
    return False

def gerar_conexoes_automaticas(notas, nlp, stopwords):
    """Processa a lista de notas, adicionando links wiki [[...]] para conceitos comuns entre notas.

    Retorna a lista de notas com seus conte√∫dos atualizados com os links adicionados.
    O processamento envolve:
    - Extra√ß√£o de conceitos-chave de cada nota (ignorando stopwords).
    - Identifica√ß√£o de conceitos compartilhados entre notas diferentes.
    - Inser√ß√£o de links no conte√∫do das notas onde esses conceitos aparecem.
    """
    conceitos_por_nota = {}
    for nota in notas:
        conceitos_por_nota[nota['titulo']] = extrair_conceitos_relevantes(nlp, nota['conteudo'], stopwords)
    links_adicionados = set()
    for idx, nota in enumerate(notas):
        conteudo = nota['conteudo']
        print(f"\nProcessando nota: {nota['titulo']} ({idx + 1}/{len(notas)})")
        conceitos_nota_atual = conceitos_por_nota[nota['titulo']]
        print(f"Conceitos identificados na nota '{nota['titulo']}': {conceitos_nota_atual}")
        for conceito in conceitos_nota_atual:
            print(f"\nAnalisando conceito: '{conceito}'")
            if conceito in ['problemas']:
                print(f"‚ö†Ô∏è Ignorando o conceito gen√©rico '{conceito}'.")
                continue
            for other_title, other_concepts in conceitos_por_nota.items():
                if other_title != nota['titulo'] and conceito in other_concepts:
                    if verificar_conexoes_relevantes(conceito, conteudo):
                        link_markup = f'[[{conceito}]]'
                        print(f"üîó Link sugerido para '{conceito}' em '{nota['titulo']}' -> {link_markup}")
                        if re.search(rf'\b{re.escape(conceito)}\b', conteudo):
                            conteudo = re.sub(rf'\b{re.escape(conceito)}\b', link_markup, conteudo)
                            links_adicionados.add(conceito)
        nota['conteudo'] = conteudo
        status = '‚úîÔ∏è' if links_adicionados else '‚ùå'
        print(f"\n{status} Processamento conclu√≠do para {nota['titulo']}")
        print(f"Links adicionados at√© agora: {len(links_adicionados)}")
    print("\n" + "="*50)
    print("PROCESSAMENTO COMPLETO")
    print("="*50)
    return notas

def criar_indice_embeddings(model, titulos):
    """Cria um √≠ndice de similaridade para t√≠tulos das notas usando embeddings.

    Retorna uma tupla (index, embeddings) onde index √© um √≠ndice FAISS treinado e embeddings √© a matriz de embeddings dos t√≠tulos.
    """
    if not titulos:
        return None, None
    embeddings = model.encode(titulos)
    index = faiss.IndexFlatL2(embeddings.shape[1])
    index.add(embeddings.astype('float32'))
    print(f"√çndice FAISS criado com {len(titulos)} embeddings de t√≠tulos.")
    return index, embeddings

def encontrar_titulo_semelhante(model, index, arquivos, frase, threshold):
    """Encontra o t√≠tulo de nota mais semelhante a uma frase fornecida usando o √≠ndice de embeddings.

    Retorna o t√≠tulo da nota com similaridade acima do limiar especificado, ou None se n√£o encontrar correspond√™ncia.
    """
    if index is None or not arquivos:
        print("‚ö†Ô∏è √çndice de t√≠tulos n√£o inicializado ou lista de notas vazia.")
        return None
    frase_limpa = re.sub(r'\n+', ' ', frase).strip().lower()
    if not frase_limpa:
        return None
    try:
        frase_embed = model.encode([frase_limpa])
        D, I = index.search(frase_embed.astype('float32'), 5)
        for i in range(len(I[0])):
            distancia = D[0][i]
            titulo_encontrado = arquivos[I[0][i]]['titulo']
            print(f"Dist√¢ncia para '{titulo_encontrado}': {distancia}")
            if distancia < threshold:
                return titulo_encontrado
    except Exception as e:
        print(f"Erro na busca por t√≠tulo semelhante '{frase}': {str(e)}")
    return None

def carregar_notas_de_diretorio(diretorio):
    """Carrega todos os arquivos .md de um diret√≥rio de notas e retorna uma lista de notas.

    Para cada arquivo Markdown encontrado, extrai o t√≠tulo (linha inicial come√ßando com '#') e o conte√∫do completo.
    Retorna uma lista de dicion√°rios, cada um contendo 'titulo', 'conteudo' e 'caminho' da nota.
    """
    notas = []
    for nome_arquivo in os.listdir(diretorio):
        if nome_arquivo.endswith(".md"):
            caminho = os.path.join(diretorio, nome_arquivo)
            try:
                with open(caminho, 'r', encoding='utf-8') as f:
                    conteudo = f.read()
            except Exception as e:
                print(f"Erro ao ler arquivo {nome_arquivo}: {e}")
                continue
            match = re.search(r'^#\s+(.+)$', conteudo, flags=re.MULTILINE)
            titulo = match.group(1).strip() if match else nome_arquivo[:-3]
            notas.append({'titulo': titulo, 'conteudo': conteudo, 'caminho': caminho})
    return notas
